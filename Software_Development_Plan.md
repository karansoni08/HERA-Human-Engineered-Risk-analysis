# ğŸ§  HERA: Human Engineered Risk Analysis  
### Software Development Plan (8 Phases)

---

## **Overview**
HERA (Human Engineered Risk Analysis) is an **LLM-assisted human-centric threat modeling system** designed to detect and quantify social engineering and insider risks.  
The project follows an **8-phase structured software development lifecycle**, integrating both deterministic analytics and AI reasoning using the **OMEÂ² Framework (Origin â€¢ Method â€¢ Exposure â€¢ Outcome)**.

---

## ğŸ—‚ï¸ **Phase 1 â€” Planning & Requirement Analysis**

### ğŸ¯ Objective
Define the overall vision, scope, and purpose of HERA, and establish project goals, deliverables, and success metrics.

### ğŸ§© Key Tasks
- Define the purpose: Quantify human-driven cyber risks using behavioral and policy data.  
- Identify stakeholders: Cybersecurity analysts, compliance officers, researchers.  
- Document functional and non-functional requirements.  
- Determine tech stack: Python, Pandas, JSON, LLM (Ollama/Mistral), Matplotlib, ReportLab.  
- Establish evaluation metrics (HTI accuracy, LLM JSON validity, reporting quality).

### ğŸ“¦ Deliverables
- Project Charter  
- Requirement Specification Document  
- Data Schema Design (CSV structures)  
- Defined OMEÂ² framework model

### ğŸ› ï¸ Tools
Miro / Lucidchart (brainstorming), Markdown / Docs for documentation.

### âœ… Outcome
A clear, actionable project blueprint defining the â€œwhat,â€ â€œwhy,â€ and â€œhowâ€ of HERA.

---

## **Phase 2 â€” System Design & Architecture**

### ğŸ¯ Objective
Develop the technical architecture, module hierarchy, and data flow for HERA.

### ğŸ§© Key Tasks
- Design the overall system architecture (Data â†’ Analytics â†’ LLM â†’ Visualization).  
- Define module dependencies and interfaces.  
- Create the OMEÂ² data model (Origin, Method, Exposure, Outcome).  
- Establish project folder structure: `/data`, `/src`, `/outputs`, `/docs`.  
- Specify JSON schemas for LLM outputs (policy_rules, scenarios, triage, guidance).

### ğŸ“¦ Deliverables
- `ARCHITECTURE.md` with diagrams  
- OMEÂ² data and class models  
- Defined JSON schemas and configuration templates

### ğŸ› ï¸ Tools
Mermaid, Draw.io, Markdown, UML diagrams.

### âœ… Outcome
A scalable and modular blueprint ensuring system clarity and extensibility.

---

## **Phase 3 â€” Data Layer Development**

### ğŸ¯ Objective
Build the synthetic data generation and ingestion pipeline for safe, realistic datasets.

### ğŸ§© Key Tasks
- Implement `generate_synthetic_data.py` using **Faker** and **Random**.  
- Create CSVs:
  - `user_directory.csv`
  - `phishing_simulation.csv`
  - `access_logs.csv`
  - `policy_violations.csv`  
- Validate schema using **Pydantic** or **Pandera**.  
- Generate 100â€“300 synthetic user profiles with varied behaviors.

### ğŸ“¦ Deliverables
- `/data` directory with populated synthetic datasets  
- Schema validation scripts and logs  
- Data generation documentation

### ğŸ› ï¸ Tools
Python, Pandas, Faker, Pandera.

### âœ… Outcome
A privacy-safe, fully synthetic dataset representing realistic enterprise activity.

---

## **Phase 4 â€” Analytics & Scoring Engine**

### ğŸ¯ Objective
Develop the deterministic analytics engine that computes risk scores and maps threats using the OMEÂ² model.

### ğŸ§© Key Tasks
- Implement `feature_engineering.py` (behavioral metrics extraction).  
- Create `score_risk.py` to compute **Human Threat Index (HTI)**:  
  `HTI = Likelihood Ã— Impact Ã— (1 - Detectability)`  
- Map risk signals to OMEÂ² pillars with `map_ome2_vectors.py`.  
- Test and calibrate thresholds for role-based accuracy.

### ğŸ“¦ Deliverables
- `risk_scores.csv` output  
- Analytics engine scripts  
- Unit tests for calculations

### ğŸ› ï¸ Tools
Python, Pandas, Numpy, JSON.

### âœ… Outcome
An explainable scoring engine that quantifies human risk with precision and transparency.

---

## **Phase 5 â€” LLM Intelligence Layer**

### ğŸ¯ Objective
Integrate large language models for policy understanding, scenario generation, triage summarization, and mitigation coaching.

### ğŸ§© Key Tasks
1. **Policy â†’ Control Extraction (`llm_extract_policy_rules.py`)**  
   Converts unstructured policies into structured JSON control rules.  
2. **Attack Scenario Generator (`llm_generate_scenarios.py`)**  
   Creates realistic department-specific attack narratives.  
3. **Analyst Summarizer (`llm_summarize_triage.py`)**  
   Produces SOC-style summaries from raw activity logs.  
4. **Mitigation Coach (`llm_generate_guidance.py`)**  
   Generates tailored awareness messages and control recommendations.  

### ğŸ“¦ Deliverables
- `policy_rules.json`  
- `scenarios/*.json`, `triage/*.json`, `guidance/*.json`  
- Prompt templates and validation logs

### ğŸ› ï¸ Tools
Ollama (LLaMA 3 / Mistral), Python (requests/jsonschema).

### âœ… Outcome
An AI-assisted reasoning layer that transforms data into contextual and actionable intelligence.

---

## **Phase 6 â€” Visualization & Reporting**

### ğŸ¯ Objective
Visualize insights and generate professional-grade executive reports.

### ğŸ§© Key Tasks
- Build `visualize.py` for:
  - Risk heatmaps by department  
  - Top risky identities  
  - Phishing behavior trends  
- Create `report_builder.py` to compile:
  - Figures + JSON insights â†’ PDF/Markdown  
  - Include LLM summaries and ethics appendix  

### ğŸ“¦ Deliverables
- `charts/*.png`  
- `human_threat_model_report.pdf`  
- Report templates (Jinja2/ReportLab)

### ğŸ› ï¸ Tools
Matplotlib, Plotly, ReportLab, Jinja2.

### âœ… Outcome
An interpretable, visual report translating analytics into executive-ready intelligence.

---

## **Phase 7 â€” Testing, Validation & Quality Assurance**

### ğŸ¯ Objective
Verify system correctness, robustness, and ethical compliance.

### ğŸ§© Key Tasks
- Conduct **functional and unit testing** for each module.  
- Validate all LLM outputs against strict JSON schemas.  
- Measure model consistency (temperature = 0â€“0.2).  
- Conduct **ethics and fairness review** using simulated edge cases.  

### ğŸ“¦ Deliverables
- `/tests` folder with automated scripts  
- QA report (accuracy, reproducibility, bias metrics)  
- Compliance and ethics statement  

### ğŸ› ï¸ Tools
PyTest, JSONSchema, Flake8, Black.

### âœ… Outcome
A stable, reproducible, bias-free system ready for deployment and presentation.

---

## **Phase 8 â€” Deployment, Documentation & Maintenance**

### ğŸ¯ Objective
Prepare HERA for deployment, public release, and long-term sustainability.

### ğŸ§© Key Tasks
- Finalize all documentation (`README.md`, `ARCHITECTURE.md`, `SOFTWARE_DEVELOPMENT_PLAN.md`).  
- Create `requirements.txt` and setup guide.  
- Package sample reports and datasets for demo.  
- Optional: containerize project using Docker.  
- Plan maintenance tasks (LLM retraining, dataset refresh).  

### ğŸ“¦ Deliverables
- Complete GitHub repository  
- Final documentation set  
- Optional Docker container  
- Demo-ready environment  

### ğŸ› ï¸ Tools
Git, GitHub Actions, Docker (optional), Markdown.

### âœ… Outcome
A production-ready, well-documented project repository suitable for academic submission or professional demonstration.

---

## ğŸ—“ï¸ **Timeline Overview (8 Weeks)**

| Phase | Duration | Deliverable |
|-------|-----------|-------------|
| **1. Planning** | Week 1 | Requirement & Scope Document |
| **2. System Design** | Week 2 | Architecture Blueprint |
| **3. Data Layer** | Week 3 | Synthetic Data Generator |
| **4. Analytics Engine** | Week 4 | HTI & OMEÂ² Mapping Engine |
| **5. LLM Layer** | Weeks 5â€“6 | AI-Driven Intelligence Modules |
| **6. Visualization** | Week 7 | Charts & Executive Report |
| **7. Testing/QA** | Week 7â€“8 | Validation Report |
| **8. Deployment** | Week 8 | Final Repository & Documentation |

---

## ğŸ§¾ **Final Deliverables Summary**

- âœ… **Executable Codebase:** `/src`, `/data`, `/outputs`, `/docs`  
- âœ… **LLM Modules:** Policy Extraction, Scenario, Triage, Guidance  
- âœ… **Analytics Engine:** HTI computation and OMEÂ² mapping  
- âœ… **Report Outputs:** Charts, dashboards, and executive PDF  
- âœ… **Documentation:** README, Architecture, SDP, Ethics report  
- âœ… **Testing Suite:** QA and JSON schema validation

---

## âš–ï¸ **Ethics & Compliance**
HERA is designed under a strict privacy-first principle:
- Uses **synthetic data only** â€” no personal or organizational identifiers.  
- Enforces **local/offline LLM inference** to prevent data exposure.  
- Includes bias-checking and fairness analysis in QA phase.  

---

## ğŸš€ **Outcome**
By the end of the development cycle, **HERA** will deliver:
- A functional AI-assisted platform that models human-centric risks.  
- A robust data analytics and visualization framework.  
- Executable LLM intelligence modules for automated policy reasoning and narrative reporting.  
- A reproducible and ethical research-grade cybersecurity tool.

---
